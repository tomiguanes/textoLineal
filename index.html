<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>El Futuro de la IA</title>
    <link rel="stylesheet" href="style.css">
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background-color: #f4f4f4;
            margin: 0;
            padding: 20px;
            text-align: center;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: white;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            text-align: left; /* Para que el texto no esté todo centrado */
        }

        h1, h2 {
            text-align: center;
            color: #333;
        }

        p {
            line-height: 1.6;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>The Future of Computer Intelligence is Everything But Artificial</h1>
        <p>Despite a flood of Sunday morning hype, it’s questionable whether computers crossed an artificial intelligence threshold last weekend. However, the news about a chatbot with the personality of a 13-year-old Ukrainian boy passing the Turing test did get us thinking: Is tricking every third human in a text exchange really the best way to measure computer intelligence?</p>
        <p>Computers are already smart, just in their own ways. They catalogue the breadth of human knowledge, find meaning in mushroom clouds of data, and fly spacecraft to other worlds. And they’re getting better. Below are four domains of computing where the machines are rising.</p>

        <h2>Information Retrieval</h2>
        <p>Given the right set of rules, computers are the ultimate librarians. Google’s search algorithm shakes down 50 billion web pages every time you need to prove your boyfriend wrong about his latest baseless assertion. It’s so good at its job that many people consider clicking to the second page of search results an act of desperation.</p>
        <p><strong>Where it’s headed:</strong> Understanding human language is one of the most difficult things computers can do. Unlike us, computers struggle to understand how a word can change meaning depending on its neighbors, says Russ Altman, a biomedical informatics researcher at Stanford. Solving this problem is Altman’s obsession. Since 2000, he and his colleagues have been teaching a machine how to get meaning from some of the densest language on the planet: medical journalese.</p>

        <h2>Robotics</h2>
        <p>Robots that work in controlled environments, like car manufacturing plants, are impressive enough. But getting them to do programmed tasks alongside humans, who have complex behaviors, is one of the most difficult challenges in computing. The vanguard of intelligent robotics are droids that let humans do tasks that require creative thought or fine manipulation and fill in the organization and heavy lifting where needed.</p>
        <p><strong>Where it’s headed:</strong> Researchers are getting better at teaching robots how to read the syntax of human movement, so they can work more closely on more complicated projects. David Bourne, a roboticist at Carnegie-Mellon University’s Robotics Institute, says the key is to play to both the human and robot strengths. “A person is actually more dexterous, but a robot can move to an exact position really well.” Bourne made a robotic arm that assists automobile welders. In a trial, the human-robot team assembled a Hummer frame. The robot had a video projector that showed the human exactly where to put different parts and then made perfect, 5-second welds. For more difficult welds, it deferred to its partner. “Together they were able to do the project 10 times faster than a team of three human professionals,” says Bourne.</p>

        <h2>Machine Learning</h2>
        <p>Machine learning is a sub-discipline of AI that uses trial-and-error to figure out complex problems. For example, a cloud service might spend a weekend feeding House of Cards to half a million people, or run through millions of iterations to help a lending bank evaluate credit risk scenarios. Getting data to flow to the right places requires constant adaptation to respond to the network’s shifting bandwidth bottlenecks. Cloud providers like Amazon use algorithms to learn from the varying demands, so the bitrate stays high.</p>
        <p><strong>Where it’s headed:</strong> Machine learning isn’t just keeping the cloud clutter-free; it’s going to turn smart phones into geniuses. Current machine learning programs can require hundreds or thousands of iterations, but researchers are building animal-inspired algorithms that can learn good from bad after only a few trials.</p>

        <h2>Better Brains</h2>
        <p>Computers have come a long way in interpreting complex inputs like sound, movement, and image recognition. But there’s room to grow: Siri still makes mistakes, Kinect hasn’t totally revolutionized gaming, and Google needed 16,000 processors to train a computer to identify cat videos on YouTube. This is mostly because things like language and kittens can’t be easily reduced to binary equations.</p>
        <p><strong>Where it’s headed:</strong> Several researchers are trying to create chips that work more like brains than calculators. This field is called neuromorphic computing. Like a brain, a neural processing unit (NPU) processes many different data streams at the same time. The end goal is to have devices that can read complex sensory information (like voices and flailing limbs) at a fraction of the computational cost of traditional chips. This means that Siri’s daughter will be able to answer your questions faster, with less prompting, and without being as much of a drain on your battery. These NPUs will run alongside traditional, binary CPUs, which will still be essential for running things like operating systems and tip calculators.</p>
    </div>
</body>
</html>
